{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33aae22-bd49-42b2-b417-27f6dbf67e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install swig\n",
    "#!pip install Boost\n",
    "#!pip install xylib-py\n",
    "# !git clone https://github.com/wojdyr/xylib.git\n",
    "# !pip install git+https://github.com/wojdyr/xylib.git\n",
    "# !python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd6c630-ce02-4b2b-8346-984a71256fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xylib as xy\n",
    "\n",
    "import glob, os \n",
    "\n",
    "#data management\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "#plotting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24fb170-8a2b-434f-9cd2-693f902b3dfb",
   "metadata": {},
   "source": [
    "xylib is a library for reading files that contain x-y data from powder diffraction, spectroscopy or other experimental methods.\n",
    "It is recommended to set LC_NUMERIC=\"C\" (or other locale with the same numeric format) before reading files.  Usually, we first call load_file() to read file from disk. It stores all data from the file in class DataSet.\n",
    "  DataSet contains a list of Blocks, each Blocks contains a list of Columns,\n",
    "  and each Column contains a list of values.\n",
    " \n",
    "  It may sound complex, but IMO it can't be made simpler.\n",
    "  It's analogical to a spreadsheet. One OOCalc or Excel file (which\n",
    "  corresponds to xylib::DataSet) contains a number of sheets (Blocks),\n",
    "  but usually only one is used. Each sheet can be viewed as a list of columns.\n",
    " \n",
    "  In xylib all columns in one block must have equal length.\n",
    "  Several filetypes always contain only one Block with two Columns.\n",
    "  In this case we can take coordinates of the 15th point as:\n",
    "     double x = get_block(0)->get_column(1)->get_value(14);\n",
    "     double y = get_block(0)->get_column(2)->get_value(14);\n",
    "  Note that blocks and points are numbered from 0, but columns are numbered\n",
    "  from 1, because the column 0 returns index of point.\n",
    "  All values are stored as floating-point numbers, even if they are integers\n",
    "  in the file.\n",
    "  DataSet and Block contain also MetaData, which is a string to string map.\n",
    " \n",
    "  Note that C++ API uses std::string and exceptions, so it is recommended\n",
    "  to compile the library and programs that use it with the same compiler.\n",
    " \n",
    "  C++ API is defined in xylib namespace, C API use prefix xylib.\n",
    " /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77608b42-2583-48fe-a8d0-5bb1044a409c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def __searchFile(mainDir: str, subDirs: list = [''], selected_file: list = [], extensions: list = ['.raw'], recursive: bool = False, debug: bool = False):\n",
    "    \"\"\"\n",
    "    Look inside the folder specified to generate the list of filenames.\n",
    "    \n",
    "    - Arguments:\n",
    "    mainDir: str, \n",
    "    subDirs: list = [], \n",
    "    selected: list = [], \n",
    "    extensions: str = '.raw', \n",
    "    \n",
    "    - Return:\n",
    "    selected: list of found filenames\n",
    "    \"\"\"\n",
    "    if debug:\n",
    "        print(f\"\"\"\n",
    "        mainDir: {mainDir},\n",
    "        subDirs: {subDirs},\n",
    "        selected_file: {selected_file},\n",
    "        extensions: {extensions},\n",
    "        recursive: {recursive}, \n",
    "        debug: {debug}\n",
    "        \"\"\")\n",
    "    \n",
    "    #variable declaration\n",
    "    selected = []  #container for loaded filenames\n",
    "    \n",
    "    #troubleshoot arguments\n",
    "    if type(subDirs) != list:\n",
    "        warnings.warn('subDirs should be a list. Now is converted to a list')\n",
    "        subDirs = [subDirs]\n",
    "    else:\n",
    "        if len(subDirs) == 0:\n",
    "            warnings.warn('detected empy subDirs list, set it to empty string \\'\\'')\n",
    "            subDirs = ['']\n",
    "    if type(selected_file) != list:\n",
    "        warnings.warn('selected should be a list. Now is converted to a list') \n",
    "        selected_file=[selected_file]\n",
    "    if type(extensions) != list:\n",
    "        warnings.warn('ext should be a list. Now is converted to a list')\n",
    "        extensions=[extensions]\n",
    "\n",
    "    #import files in selected \n",
    "    if len(selected_file) == 0:\n",
    "        #No user-defined request\n",
    "        if debug:\n",
    "            print(f\" - __searchFile: looking inside specified subfolders of mainDir and their sobfolders\")\n",
    "        for subDir in subDirs:\n",
    "            #look into all subfolders\n",
    "            if subDir != '' and subDir.endswith('/') == False:\n",
    "                subDir = subDir + '/'\n",
    "            if debug:\n",
    "                print(f\" - __searchFile: looking in {subDir} subfolder\")\n",
    "            if recursive:\n",
    "                for extension in extensions:\n",
    "                    print(mainDir+subDir)\n",
    "                    selections = glob.glob(mainDir+subDir+'**/*'+extension, recursive=recursive)   # if filenames is empty, take all folders/files inside maindir\n",
    "                    for selection in selections:\n",
    "                        selected.append(selection)    #ensure selected is a list of str not a list of list \n",
    "            else:\n",
    "                if debug:\n",
    "                    print(f\" - __searchFile: looking only inside the spcified subfolders of mainDir.\")           \n",
    "                for extension in extensions:\n",
    "                    selections = glob.glob(mainDir+subDir+'*'+extension, recursive=recursive)   # if filenames is empty, take all folders/files inside maindir          \n",
    "                    for selection in selections:\n",
    "                        selected.append(selection)    #ensure selected is a list of str not a list of list \n",
    "    else:\n",
    "        if debug:\n",
    "            print(\" - __searchFile: loading user selected files\")\n",
    "        for file in selected_file:\n",
    "            file = mainDir+file\n",
    "            if debug:\n",
    "                print(f\" - __searchFile: looking for {file}\")\n",
    "            if os.path.exists(file) == True:\n",
    "                selections = glob.glob(file, recursive=recursive)\n",
    "                for selection in selections:\n",
    "                    selected.append(selection)    #ensure selected is a list of str not a list of list \n",
    "            else:\n",
    "                for extension in extensions: \n",
    "                    if debug:\n",
    "                        print(f\" - __searchFile: looking for {file+extension}\")\n",
    "                    selections = glob.glob(file+extension, recursive=recursive) # if file doesn't exist, returns an empty list\n",
    "                for selection in selections:\n",
    "                    selected.append(selection)    #ensure selected is a list of str not a list of list \n",
    "        \n",
    "    #sort selected files\n",
    "    selected.sort()\n",
    "    if debug:\n",
    "        print(f\" - __searchFile: found {len(selected)} files\")\n",
    "    return selected\n",
    "        \n",
    "def raw2xyN(mainDir: str, subDirs: list = [], selected_file: list = [], ext: str = '.raw', recursive: bool = False, optimize: bool = True, convertraw: bool = True, expInSubDir: bool = False, debug: bool = False):\n",
    "    \"\"\"\n",
    "    Convert given .raw files into .xy and .xyn files. .xyn files are normalized data \n",
    "    for the time per step used during the data acquisition. The methods then save the read files as .xy and .xyn in the same folder or in a subfolder named ./exported\n",
    "    \n",
    "    - Arguments\n",
    "    mainDir: str, \n",
    "    subDirs: list = [], \n",
    "    selected: list = [], \n",
    "    ext: str = '.raw', \n",
    "    optimize: bool = True, check if converted files .xy, .xyn exists. in that case avoid conversion \n",
    "    convertraw: bool = True, \n",
    "    expInSubDir: bool = False, \n",
    "    debug: bool = False):\n",
    "    \n",
    "    - Return\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    nConverted = 0\n",
    "    formatErrors = 0 # to count the number of errors in the conversion procedure due to non-supported raw files.\n",
    "    formatErrorsFilename = [] # track filenames which are in unsupoprte format\n",
    "    convertedFilenames = [] # track filenames which are in unsupoprte format\n",
    "    expInSubDir = expInSubDir\n",
    "    \n",
    "    import xylib as xy\n",
    "\n",
    "    #variable declaration\n",
    "    paths = []\n",
    "    files = []  #is a list of filenames choosen\n",
    "    dataset = []  #is a list of np.array rapresenting the whole dataset\n",
    "    \n",
    "    \n",
    "    selected = __searchFile(mainDir = mainDir, subDirs = subDirs, selected_file = selected_file,\n",
    "                            extensions = ext, recursive = recursive, debug = debug)\n",
    "    selectedXY = __searchFile(mainDir = mainDir, subDirs = subDirs, selected_file = selected_file,\n",
    "                             extensions = ['.xy'], recursive = recursive, debug = debug)\n",
    "    selectedXYN = __searchFile(mainDir = mainDir, subDirs = subDirs, selected_file = selected_file,\n",
    "                            extensions = ['.xyn'], recursive = recursive, debug = debug)\n",
    "    if debug:\n",
    "        print(f'sorting the {len(selected)} selected files by the name:', selected)\n",
    "\n",
    "    if optimize:\n",
    "        #look for already converted files. delete those from selected list\n",
    "        selectedToRemove = []   #container for the indexes to be removed\n",
    "        selectedNormalizedToRemove = []  #container for the indexes with .xyn extension already present to be removed\n",
    "        discardedFilenames = [] # track filenames which are already converted\n",
    "        for i in range(0,len(selected)):\n",
    "            if selected[i][:-3]+'xy' in selectedXY:\n",
    "                selectedToRemove.append(i)\n",
    "            if selected[i][:-3]+'xyn' in selectedXYN:\n",
    "                selectedNormalizedToRemove.append(i)   #future development, detect which raw are not converted as normalized, then export the converted raw ONLY aas .xyn\n",
    "        if len(selectedToRemove) != 0:\n",
    "            if debug:\n",
    "                print(f\"found {len(selectedToRemove)} already converted files\")\n",
    "            for index in range(1, len(selectedToRemove)+1):\n",
    "                selectedDiscard = selected.pop(len(selectedToRemove)-index)  #pop items on reverse so that indexes won't change during the popping procedure.\n",
    "                discardedFilenames.append(os.path.basename(selectedDiscard))\n",
    "            selected.sort()\n",
    "            if debug:\n",
    "                print(f'sorting the {len(selected)} updated selected files by the name:', selected)\n",
    "    \n",
    "    #start the conversion\n",
    "    for pathFile in selected:\n",
    "        if debug:\n",
    "            print(f'converting {os.path.basename(pathFile)}\\n')\n",
    "        try:\n",
    "            file = xy.load_file(pathFile)\n",
    "        except RuntimeError:\n",
    "            warnings.warn('File conversion error.')\n",
    "            print(f\"!!! raw format not supported for {os.path.basename(pathFile)}\")\n",
    "            formatErrors +=1\n",
    "            formatErrorsFilename.append(os.path.basename(pathFile))\n",
    "            continue \n",
    "\n",
    "        #usually raws are made of 1 block\n",
    "        block = file.get_block(0)\n",
    "\n",
    "        #extract the two columns, even though seems that col1 doesn't contain 2theta values\n",
    "        col1 = block.get_column(1)\n",
    "        col2 = block.get_column(2)\n",
    "        if debug:\n",
    "            print(f\"file: {file}, n blocks: {file.get_block_count()}, n cols in block: {block.get_column_count()}\")\n",
    "\n",
    "        #extract meta information from which we can build-up 2theta axis.\n",
    "        meta = block.meta\n",
    "        keys = []   #container for keys\n",
    "\n",
    "        #get the keys' name\n",
    "        for i in range(0,12):\n",
    "            keys.append(meta.get_key(i))\n",
    "\n",
    "        #loop over keys to get their values\n",
    "        for key in keys:\n",
    "            if debug:\n",
    "                print(key ,meta.get(key))\n",
    "        startth = float(meta.get('START_2THETA'))\n",
    "        stepsize = float(meta.get('STEP_SIZE'))\n",
    "        nstep = float(meta.get('STEPS'))\n",
    "        tps = float(meta.get('TIME_PER_STEP'))\n",
    "        lam = float(meta.get('USED_LAMBDA'))\n",
    "\n",
    "        # create np array for x\n",
    "        npx = np.arange(startth,startth+stepsize*nstep,stepsize)\n",
    "        if debug:\n",
    "            print(f\"{np.shape(npx)} points on x axis\" )\n",
    "            print(f\"x values loaded from {npx[0]} to {npx[-1]} with stepsize {npx[1]-npx[0]}\")\n",
    "\n",
    "        # extract y values\n",
    "        valy = []\n",
    "        for index in range(0, col2.get_point_count()):\n",
    "            valy.append(col2.get_value(index))\n",
    "\n",
    "        # create numpy array\n",
    "        npy = np.array(valy)\n",
    "        if debug:\n",
    "            print(f\"{np.shape(npy)} points on y axis\" )\n",
    "        npnorm = npy/tps   #normalize for time per step\n",
    "\n",
    "        #build the dataset\n",
    "        if np.shape(npy) != np.shape(npx):\n",
    "            dataset = [npx[:-1], npy, npnorm]   #usually x points are 1 time longer.\n",
    "        else:\n",
    "            dataset = [npx, npy, npnorm]\n",
    "\n",
    "        #generate np.array\n",
    "        npdataset = np.array(dataset).T\n",
    "\n",
    "        #build the head of the final .xy files\n",
    "        head = f\"time per step: {tps}\\nlambda: {lam}\\n2theta Counts NormalizedCounts\"\n",
    "\n",
    "\n",
    "        if expInSubDir == True:\n",
    "            if not os.path.exists(path+'/export'):\n",
    "                !mkdir {'\\''+pathFile.strip(os.path.basename(pathFile))+'export/'+'\\''}\n",
    "            fnameXY = path+'export/'+os.path.basename(pathFile)[0:-4]+'.xy'\n",
    "            fnameXYN = path+'export/'+os.path.basename(pathFile)[0:-4]+'.xyn'\n",
    "        else:\n",
    "            fnameXY = pathFile[0:-4]+'.xy'\n",
    "            fnameXYN = pathFile[0:-4]+'.xyn'\n",
    "\n",
    "        # save array to .xy file\n",
    "        np.savetxt(fname=fnameXY, X=npdataset[:,:2], header=head)\n",
    "        np.savetxt(fname=fnameXYN, X=npdataset[:,:], header=head)\n",
    "        nConverted +=1\n",
    "        convertedFilenames.append(os.path.basename(pathFile))\n",
    "    \n",
    "    if os.path.exists(\"raw2xyN.log\"):\n",
    "        with open(\"raw2xyN.log\", \"w\") as f:\n",
    "            f.write(str(nConverted) +\" files succesfully converted \\n \"+ str(formatErrors) +\"  files are in a non-supported format \\n\" + str(len(discardedFilenames)) + \" have been discarded\")\n",
    "            f.write(\"\\n\\n##########################################\\n converted files: \\n\")\n",
    "            for item in convertedFilenames:\n",
    "                # write each item on a new line\n",
    "                f.write(\"%s\\n\" % item)\n",
    "            f.write(\"\\n\\n##########################################\\n files in a non-supported format: \\n\")\n",
    "            for item in formatErrorsFilename:\n",
    "                # write each item on a new line\n",
    "                f.write(\"%s\\n\" % item)\n",
    "            f.write(\"\\n\\n##########################################\\n files discarded: \\n\")\n",
    "            for item in discardedFilenames:\n",
    "                # write each item on a new line\n",
    "                f.write(\"%s\\n\" % item)\n",
    "                \n",
    "    else:\n",
    "        with open(\"raw2xyN.log\", \"x\") as f:\n",
    "            f.write(str(nConverted) +\" files succesfully converted \\n \"+ str(formatErrors) +\"  files are in a non-supported format \\n\" + str(len(discardedFilenames)) + \" have been discarded\")\n",
    "            f.write(\"\\n\\n##########################################\\n converted files: \\n\")\n",
    "            for item in convertedFilenames:\n",
    "                # write each item on a new line\n",
    "                f.write(\"%s\\n\" % item)\n",
    "            f.write(\"\\n\\n##########################################\\n files in a non-supported format: \\n\")\n",
    "            for item in formatErrorsFilename:\n",
    "                # write each item on a new line\n",
    "                f.write(\"%s\\n\" % item)\n",
    "            f.write(\"\\n\\n##########################################\\n files discarded: \\n\")\n",
    "            for item in discardedFilenames:\n",
    "                # write each item on a new line\n",
    "                f.write(\"%s\\n\" % item)\n",
    "    print('###########################################################################\\n')\n",
    "    print(f'Procedure terminated with {formatErrors} errors due to non-supported files. \\n{nConverted} files have been converted.\\n{len(discardedFilenames)} have been discarded.\\nFor additional details inspect the .log file')\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b4bc02-7607-4888-92f8-413b0dc724c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw2xyN(mainDir = 'path to main Dir', ext = '.raw', recursive = True, \n",
    "        optimize = True, convertraw = convertraw, expInSubDir = False, debug = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
