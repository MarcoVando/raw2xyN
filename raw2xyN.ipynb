{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pJgP20zcjlIP",
    "outputId": "c44519b0-42a9-422c-aef0-6463e23001ae"
   },
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8XNWp0CDsWz6",
    "outputId": "cf62d3dc-dcdc-420a-e7d0-3a5bdf82d02a"
   },
   "outputs": [],
   "source": [
    "!pip install swig\n",
    "!pip install Boost\n",
    "!pip install xylib-py\n",
    "# !git clone https://github.com/wojdyr/xylib.git\n",
    "# !pip install git+https://github.com/wojdyr/xylib.git\n",
    "# !python setup.py install\n",
    "\n",
    "!pip install swig Boost \n",
    "export PATH=$PATH:\n",
    "!pip install xylib-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j55K3z0uko5E"
   },
   "outputs": [],
   "source": [
    "import xylib as xy\n",
    "\n",
    "import glob, os \n",
    "\n",
    "#data management\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "#plotting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YhlO1iH9oCE8"
   },
   "source": [
    "xylib is a library for reading files that contain x-y data from powder diffraction, spectroscopy or other experimental methods.\n",
    "It is recommended to set LC_NUMERIC=\"C\" (or other locale with the same numeric format) before reading files.  Usually, we first call load_file() to read file from disk. It stores all data from the file in class DataSet.\n",
    "  DataSet contains a list of Blocks, each Blocks contains a list of Columns,\n",
    "  and each Column contains a list of values.\n",
    " \n",
    "  It may sound complex, but IMO it can't be made simpler.\n",
    "  It's analogical to a spreadsheet. One OOCalc or Excel file (which\n",
    "  corresponds to xylib::DataSet) contains a number of sheets (Blocks),\n",
    "  but usually only one is used. Each sheet can be viewed as a list of columns.\n",
    " \n",
    "  In xylib all columns in one block must have equal length.\n",
    "  Several filetypes always contain only one Block with two Columns.\n",
    "  In this case we can take coordinates of the 15th point as:\n",
    "     double x = get_block(0)->get_column(1)->get_value(14);\n",
    "     double y = get_block(0)->get_column(2)->get_value(14);\n",
    "  Note that blocks and points are numbered from 0, but columns are numbered\n",
    "  from 1, because the column 0 returns index of point.\n",
    "  All values are stored as floating-point numbers, even if they are integers\n",
    "  in the file.\n",
    "  DataSet and Block contain also MetaData, which is a string to string map.\n",
    " \n",
    "  Note that C++ API uses std::string and exceptions, so it is recommended\n",
    "  to compile the library and programs that use it with the same compiler.\n",
    " \n",
    "  C++ API is defined in xylib namespace, C API use prefix xylib.\n",
    " /"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65N-BJVQfppD"
   },
   "source": [
    "Read file and get block and the two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wrzEJtsik0mM",
    "outputId": "82cb2cff-f93a-45ff-9224-35bcf99f46d3"
   },
   "outputs": [],
   "source": [
    "filename = 'FILENAME.raw'\n",
    "file1= xy.load_file('./' + filename)\n",
    "\n",
    "print(file1.get_block_count())\n",
    "block = file1.get_block(0)\n",
    "print(block.get_column_count())\n",
    "col1 = block.get_column(1)\n",
    "col2 = block.get_column(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZAzP_D-fDwl"
   },
   "source": [
    "Get metadata from which u can obtain the x axis (seems that col1 is not accessible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NiXjRFaiVHx3",
    "outputId": "6827001a-1024-424a-92e9-3659c59ec9d1"
   },
   "outputs": [],
   "source": [
    "print(block.get_name())\n",
    "meta = block.meta\n",
    "type(meta)\n",
    "\n",
    "keys = []\n",
    "\n",
    "#get the keys name\n",
    "for i in range(0,12):\n",
    "  keys.append(meta.get_key(i))\n",
    "\n",
    "#loop over keys to get their values\n",
    "for key in keys:\n",
    "  print(key ,meta.get(key))\n",
    "startth = meta.get('START_2THETA')\n",
    "stepsize = meta.get('STEP_SIZE')\n",
    "nstep = meta.get('STEPS')\n",
    "\n",
    "print(type(startth), type(stepsize), type(nstep))\n",
    "print(float(startth), float(stepsize), float(nstep))\n",
    "\n",
    "startth = float(startth)\n",
    "stepsize = float(stepsize)\n",
    "nstep = float(nstep)\n",
    "\n",
    "# creat np array for x\n",
    "npx = np.arange(startth,startth+stepsize*nstep,stepsize)\n",
    "np.shape(npx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67aeHxj2gfPR"
   },
   "source": [
    "Extract y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JAzXAtDr9Lp7",
    "outputId": "192505cb-ee89-47b0-b6a8-3ea335134589"
   },
   "outputs": [],
   "source": [
    "valy = []\n",
    "\n",
    "for index in range(1, col2.get_point_count()):\n",
    "  valy.append(col2.get_value(index))\n",
    "\n",
    "# create numpy array\n",
    "npy = np.array(valy)\n",
    "\n",
    "#build the dataset\n",
    "dataset = [npx[:-1], npy]\n",
    "\n",
    "npdataset = np.array(dataset).T\n",
    "np.shape(npdataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Vf5PBKDhmRF"
   },
   "source": [
    "construct the head of the final file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4dF_GxxRhqQL"
   },
   "outputs": [],
   "source": [
    "tps = meta.get('TIME_PER_STEP')\n",
    "lam = meta.get('USED_LAMBDA')\n",
    "head = f\"time per step: {tps}\\nlambda: {lam}\\n2theta Counts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "tTmQ5zRRtim4",
    "outputId": "52583e13-c673-4b78-a1bd-8a602f5c4a5b"
   },
   "outputs": [],
   "source": [
    "# plot dataset\n",
    "plt.plot(dataset[0], dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SAlVgf9iovrw"
   },
   "source": [
    "Export and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0nTWJaItu63K"
   },
   "outputs": [],
   "source": [
    "np.savetxt(fname=filename[:-3]+\".xy\", X=npdataset, header=head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JdQsTy0xovRD"
   },
   "source": [
    "The following cell is to run the same code on multiple files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3UGCCkjQou9B",
    "outputId": "7a124f42-9cad-451f-d871-ac0f4be898ff"
   },
   "outputs": [],
   "source": [
    "########################### MODIFY THESE PRMS ###########################\n",
    "#path parameter\n",
    "mainDir = './'\n",
    "#leave empty(with no '' !!) if not used, \n",
    "subDirs = []\n",
    "\n",
    "#fill this list to run the code only for specified folders. \n",
    "selected = []    #REMEMBER to put extension. \n",
    "\n",
    "#file parameter\n",
    "ext = '.raw'\n",
    "#############################################################################\n",
    "\n",
    "#variable declaration\n",
    "paths = []\n",
    "files = []  #is a list of filenames choosen\n",
    "dataset = []  #is a list of np.array rapresenting the whole dataset\n",
    "\n",
    "#Generate the complete paths for each defined subdir\n",
    "for subDir in subDirs:\n",
    "  paths.append(mainDir+subDir)\n",
    "\n",
    "print(paths)\n",
    "\n",
    "#import files in selected \n",
    "if len(selected) == 0:\n",
    "  if len(subDirs) != 0:\n",
    "    selected = glob.glob(mainDir+'**/*'+ext, recursive=True)   # if filenames is empty, take all folders/files inside maindir\n",
    "  else:\n",
    "    selected = glob.glob(mainDir+'*'+ext, recursive=True)\n",
    "\n",
    "#sort selected files\n",
    "selected.sort()\n",
    "print(len(selected), selected)\n",
    "\n",
    "\n",
    "# create and clean export folder\n",
    "if os.path.exists('./export/'): \n",
    "  !rm -r export/ \n",
    "  !mkdir export\n",
    "else: \n",
    "  !mkdir export\n",
    "\n",
    "\n",
    "for path in selected:\n",
    "  file = xy.load_file(path)\n",
    "  #usually raws are made of 1 block\n",
    "  block = file.get_block(0)\n",
    "\n",
    "  #extract the two columns, even though seems that col1 doesn't contain 2theta values\n",
    "  col1 = block.get_column(1)\n",
    "  col2 = block.get_column(2)\n",
    "  print(f\"file: {file}, n blocks: {file.get_block_count()}, n cols in block: {block.get_column_count()}\")\n",
    "\n",
    "  #extract meta information from which we can build-up 2theeta axis.\n",
    "  meta = block.meta\n",
    "  keys = []   #container for keys\n",
    "\n",
    "  #get the keys' name\n",
    "  for i in range(0,12):\n",
    "    keys.append(meta.get_key(i))\n",
    "\n",
    "  #loop over keys to get their values\n",
    "  for key in keys:\n",
    "    print(key ,meta.get(key))\n",
    "  startth = float(meta.get('START_2THETA'))\n",
    "  stepsize = float(meta.get('STEP_SIZE'))\n",
    "  nstep = float(meta.get('STEPS'))\n",
    "  tps = float(meta.get('TIME_PER_STEP'))\n",
    "  lam = float(meta.get('USED_LAMBDA'))\n",
    "\n",
    "  # create np array for x\n",
    "  npx = np.arange(startth,startth+stepsize*nstep,stepsize)\n",
    "  print(f\"{np.shape(npx)} points on x axis\" )\n",
    "\n",
    "  # extract y values\n",
    "  valy = []\n",
    "  for index in range(1, col2.get_point_count()):\n",
    "    valy.append(col2.get_value(index))\n",
    "\n",
    "  # create numpy array\n",
    "  npy = np.array(valy)\n",
    "  print(f\"{np.shape(npy)} points on y axis\" )\n",
    "  npnorm = npy/tps\n",
    "\n",
    "  #build the dataset\n",
    "  if np.shape(npy) != np.shape(npx):\n",
    "    dataset = [npx[:-1], npy, npnorm]   #usually x points are 1 time longer.\n",
    "  else:\n",
    "    dataset = [npx, npy, npnorm]\n",
    "\n",
    "  #generate np.array\n",
    "  npdataset = np.array(dataset).T\n",
    "\n",
    "  #build the head of the final .xy files\n",
    "  head = f\"time per step: {tps}\\nlambda: {lam}\\n2theta Counts NormalizedCounts\"\n",
    "\n",
    "\n",
    "  if not os.path.exists('./export'+path):\n",
    "    !mkdir {'./export'+path.strip(os.path.basename(path))}\n",
    "\n",
    "  # save array to .xy file\n",
    "  np.savetxt(fname='./export/'+path[2:-4]+\".xy\", X=npdataset[:,:2], header=head)\n",
    "  np.savetxt(fname='./export/'+path[2:-4]+\".xyn\", X=npdataset[:,:2], header=head)\n",
    "\n",
    "  !zip -r export.zip export"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
